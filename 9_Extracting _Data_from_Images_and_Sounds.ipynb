{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Big Data HW - 9 .ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQsV2IhxcDyK",
        "colab_type": "text"
      },
      "source": [
        "**Sometimes you need to kill the session in order to read new files on Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDgpQHtAjKiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !google-drive-ocamlfuse drive\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov-j_MB3ZkTU",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZK2PUmUjKQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrdvr99LZn6f",
        "colab_type": "text"
      },
      "source": [
        "**Folder you need to create on Google Drive: datasets\\videos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dim0TGsyj6N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.sep + os.path.join('content', 'drive', 'My\\ Drive', 'datasets', 'videos').replace('\\\\', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feHF5MqnZzSn",
        "colab_type": "text"
      },
      "source": [
        "**Install some packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmwBftr5HWim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install turicreate\n",
        "!pip install face_recognition\n",
        "!pip install mhyt\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTVC0myLZ4_S",
        "colab_type": "text"
      },
      "source": [
        "**Define Kaggle API settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXnPu2X_GOOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see more details in the course first lecture\n",
        "!mkdir /root/.kaggle/\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Installing the Kaggle package\n",
        "!pip install kaggle \n",
        "\n",
        "#Important Note: complete this with your own key - after running this for the first time remmember to **remove** your API_KEY\n",
        "api_token = {\"username\":\"\",\n",
        "\"key\":\"\"}\n",
        "  # TODO: REMOVE THIS LINE!!!\n",
        "\n",
        "# creating kaggle.json file with the personal API-Key details \n",
        "# You can also put this file on your Google Drive\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "  json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6zYEE2aQcfx",
        "colab_type": "text"
      },
      "source": [
        "## Homework Assignment 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQoYOWJGQcfz",
        "colab_type": "text"
      },
      "source": [
        "**Question 1:** Select a short video with at least 3 persons and create a new movie from this video with a face tracker (each personâ€™s face needs to be tracked by a rectangle of a different color) (50pt). See, for example, the video in: https://github.com/ageitgey/face_recognition\n",
        "\n",
        "**Bonus:** Select a video with at least two animals (dog/cat/lion/tiger...), and create a video with an animal tracker (10pt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq2196I8xCLE",
        "colab_type": "text"
      },
      "source": [
        "**Upload images for each persons we want to recognize (Google Drive --> datasets\\videos\\images**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZPr8pQyPDaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import face_recognition  # requires GPUs in Colab\n",
        "\n",
        "known_faces = []\n",
        "images_folder = os.path.join(data_path, \"images\")\n",
        "names_images = {\n",
        "  'conan obrien': '3000.jpeg',\n",
        "  'James Parsons': '46844.jpg',\n",
        "  'Simon Helberg': 'Helbergrl.png'\n",
        "}\n",
        "names_colors = {\n",
        "  'conan obrien': (255, 0, 0),\n",
        "  'James Parsons': (255, 255, 0),\n",
        "  'Simon Helberg': (255, 0, 255)\n",
        "}\n",
        "names = []\n",
        "\n",
        "for name, pic in names_images.items():\n",
        "  names.append(name)\n",
        "  loaded_pic = face_recognition.load_image_file(os.path.join(images_folder, pic))\n",
        "  encoding_pic = face_recognition.face_encodings(loaded_pic)[0]\n",
        "  known_faces.append(encoding_pic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLubiEBcxM5n",
        "colab_type": "text"
      },
      "source": [
        "**Define the output files and object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRxL-TzvfoBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_people_video = \"output_people.avi\"\n",
        "# Create an output movie file (make sure resolution/frame rate matches input video!)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_movie = cv2.VideoWriter(output_people_video, fourcc, 5.0, (1920, 1080))\n",
        "\n",
        "output_people_video_mp4 = \"output_people.mp4\"\n",
        "output_people_video_gif = \"output_people.gif\"\n",
        "![ -f $output_people_video_mp4 ] && rm $output_people_video_mp4\n",
        "![ -f $output_people_video_gif ] && rm $output_people_video_gif"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9uj3l29wHCZ",
        "colab_type": "text"
      },
      "source": [
        "**Read the input video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDg9nvEhwGIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open the input movie file\n",
        "video_name = \"video_people.mp4\"\n",
        "input_people_video = os.path.join(data_path, video_name)\n",
        "input_movie = cv2.VideoCapture(input_people_video)\n",
        "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f'Number of frames: {length}')\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open(input_people_video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"1280\" height=\"720\" controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_CmtQunxSh0",
        "colab_type": "text"
      },
      "source": [
        "**Read video frame by frame and draw rectangle and text for each person we recognized and write all these new frames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC4d-whdOm3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_faces_name(face_encodings, names):\n",
        "  face_names = []\n",
        "  for face_encoding in face_encodings:\n",
        "      # See if the face is a match for the known face(s)\n",
        "      match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.80)\n",
        "\n",
        "      name = None\n",
        "      for i in range(len(match)):\n",
        "        if match[i]:\n",
        "          name = names[i]\n",
        "          break\n",
        "      face_names.append(name)\n",
        "  return face_names\n",
        "\n",
        "def clean_session(input_movie, output_movie):\n",
        "  input_movie.release()\n",
        "  output_movie.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "def plot_box(top, right, bottom, left, name, names_colors, frame, cv2):\n",
        "  if not name:\n",
        "    return\n",
        "  else:\n",
        "    r = names_colors[name][0]\n",
        "    g = names_colors[name][1]\n",
        "    b = names_colors[name][2]\n",
        "\n",
        "  # Draw a box around the face\n",
        "  cv2.rectangle(frame, (left, top), (right, bottom), (r, g, b), 2)\n",
        "\n",
        "  # Draw a label with a name below the face\n",
        "  cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (r, g, b), cv2.FILLED)\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  org = (left + 6, bottom - 6)\n",
        "  thickness = 2\n",
        "  color = (255, 255, 255)\n",
        "  cv2.putText(frame, name, org, font, 0.5, color, thickness)\n",
        "\n",
        "locations = []\n",
        "encodings = []\n",
        "face_names = []\n",
        "\n",
        "number_of_frames = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "for frame_number in tqdm(range(number_of_frames)):\n",
        "    ret, frame = input_movie.read()  # get the next frame\n",
        "    if not ret:  # in case there is no frames anymore\n",
        "        print(\"ret is None\")\n",
        "        break\n",
        "\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # Find all the faces and face encodings in the current frame of video\n",
        "    locations = face_recognition.face_locations(rgb_frame)\n",
        "    encodings = face_recognition.face_encodings(rgb_frame, locations)\n",
        "    face_names = get_faces_name(encodings, names)\n",
        "\n",
        "    for (top, right, bottom, left), name in zip(locations, face_names):\n",
        "      plot_box(top, right, bottom, left, name, names_colors, frame, cv2)\n",
        "\n",
        "    output_movie.write(frame)  # Write the resulting image to the output video file\n",
        "\n",
        "clean_session(input_movie, output_movie)\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85f66Gyoxk5g",
        "colab_type": "text"
      },
      "source": [
        "**Convert AVI format to MP4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0XxqQePzubG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -i $output_people_video $output_people_video_mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC3pGgQRyRP5",
        "colab_type": "text"
      },
      "source": [
        "**Present the output video (I ignored the woman on the left side since she is not a celebrity)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLWHZNu4xwhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open(output_people_video_mp4,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"1280\" height=\"720\" controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRlwz7vgxx93",
        "colab_type": "text"
      },
      "source": [
        "**Convert AVI to GIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwh8hG_DwNYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -i $output_people_video $output_people_video_gif"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4d-dlZ0f0U6",
        "colab_type": "text"
      },
      "source": [
        "**Present the GIF output (from my Github):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxxOJ_vSfzj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://github.com/nevoit/Analyzing-Big-Data-Course/raw/master/figures/hw_9_gif.gif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWWU1E43Qcf5",
        "colab_type": "text"
      },
      "source": [
        "**Question 2:** Select a collection of connected images. Create a graph of the links among images or objects in images (42pt). Use graph algorithms to discover interesting insights regarding the images. See, for example, [Figure 2](https://arxiv.org/pdf/1509.00568.pdf) (8pt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krRUuONQglyb",
        "colab_type": "text"
      },
      "source": [
        "**Connect to kaggle and download the [simpsons datasets](https://www.kaggle.com/alexattia/the-simpsons-characters-dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do3xxLZ2Qcf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = 'simpsons'\n",
        "KAGGLE_REPO = 'alexattia/the-simpsons-characters-dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIYM_-UO9gzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# searching for the dataset\n",
        "!rm -r ./datasets/$DATASET_NAME/\n",
        "!mkdir -p ./datasets/$DATASET_NAME/data\n",
        "!mkdir -p ./datasets/$DATASET_NAME/zip\n",
        "!mkdir -p ./datasets/$DATASET_NAME/sql\n",
        "!ls datasets/$DATASET_NAME/data\n",
        "\n",
        "!kaggle datasets list -s $DATASET_NAME\n",
        "# download the dataset from Kaggle and unzip it\n",
        "!kaggle datasets download $KAGGLE_REPO -p ./datasets/$DATASET_NAME/zip\n",
        "!unzip ./datasets/$DATASET_NAME/zip/*.zip -d ./datasets/$DATASET_NAME/data\n",
        "!ls ./datasets/$DATASET_NAME/zip/\n",
        "!ls ./datasets/$DATASET_NAME/data/\n",
        "!ls ./datasets/$DATASET_NAME/sql/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGm139e4iNVZ",
        "colab_type": "text"
      },
      "source": [
        "**Read the dataset using turicreate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf2COrSo9nYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import turicreate as tc\n",
        "import turicreate.aggregate as agg\n",
        "DATASET_PATH = f\"./datasets/{DATASET_NAME}/data/simpsons_dataset\"\n",
        "\n",
        "data_perc = 0.05\n",
        "seed = 2020\n",
        "sf = tc.image_analysis.load_images(DATASET_PATH, with_path=True).sample(data_perc, seed=seed)\n",
        "sf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2I9fCWNirnn",
        "colab_type": "text"
      },
      "source": [
        "**Extract the character name using the path column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXyz2Am-BAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sf['character'] = sf['path'].apply(lambda p: p.split('/')[-2])\n",
        "sf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XpRgBi1-DU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sf[:5].explore()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNYrXw4HizrR",
        "colab_type": "text"
      },
      "source": [
        "**Let's calculate the feature vector of each image:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZVRMzK--F6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from turicreate.toolkits import _image_feature_extractor, _pre_trained_models\n",
        "\n",
        "def get_images_features_vector(dataset, target, feature=\"image\", model_name='resnet-50'):\n",
        "    #ptModel = _pre_trained_models.MODELS[model_name]()\n",
        "    ptModel = tc.toolkits._pre_trained_models.ResNetImageClassifier()\n",
        "    feature_extractor = tc.toolkits._image_feature_extractor._create_feature_extractor(model_name)\n",
        "    extracted_features = tc.SFrame({\n",
        "        target: dataset[target],\n",
        "        '__image_features__': feature_extractor.extract_features(dataset, feature),\n",
        "        })\n",
        "    dataset['image_features'] = extracted_features['__image_features__']\n",
        "    return dataset\n",
        "\n",
        "sf = get_images_features_vector(sf, 'character')\n",
        "sf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1Pmjyo-MHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sf.save('./simpsons.sframe')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxVFzwTy-epa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tc.image_similarity.create(sf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2BPobF0ZEzb",
        "colab_type": "text"
      },
      "source": [
        "**The TuriCreate API supports this type of [similar image matching](https://apple.github.io/turicreate/docs/userguide/image_similarity/). Let's use it directly:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0CAyiDR-NkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity_graph = model.similarity_graph(k=2)\n",
        "similarity_graph.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_79hx3BVjF3j",
        "colab_type": "text"
      },
      "source": [
        "**Let's use Networkx and Cytoscape to draw one of the communities of the graph:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlG0MfXE-PPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import networkx as nx\n",
        "\n",
        "g = nx.Graph()\n",
        "for v in similarity_graph.vertices['__id']:\n",
        "    g.add_node(v, attr_dict={'path':sf[v]['path'], 'character': sf[v]['character']})\n",
        "for e in similarity_graph.edges:\n",
        "    g.add_edge(e[\"__src_id\"], e[\"__dst_id\"])\n",
        "nx.info(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9r1V-qjjUo7",
        "colab_type": "text"
      },
      "source": [
        "**Find communities in graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7hCAIzeMJGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "c = list(greedy_modularity_communities(g))\n",
        "len(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBDIw09iMMgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {i: len(c[i]) for i in range(len(c))}\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-oB_anOjKvF",
        "colab_type": "text"
      },
      "source": [
        "**Create a subgraph using the first community**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coELrdVyNAws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "from numpy import sqrt\n",
        "import glob\n",
        "\n",
        "communities_num = 0\n",
        "h = g.subgraph(c[communities_num])\n",
        "nx.info(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD4Ub9n8jiZt",
        "colab_type": "text"
      },
      "source": [
        "**Plot the selected community (the subgraph) with images instead nodes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI8pmWV0RrPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig=plt.figure(figsize=(30,30))\n",
        "ax=plt.subplot(111)\n",
        "ax.set_aspect('equal')\n",
        "pos=nx.kamada_kawai_layout(h, scale=3)\n",
        "\n",
        "# draw with images on nodes\n",
        "nx.draw_networkx(h,pos,width=3,edge_color=\"r\",alpha=0.6)\n",
        "ax=plt.gca()\n",
        "fig=plt.gcf()\n",
        "trans = ax.transData.transform\n",
        "trans2 = fig.transFigure.inverted().transform\n",
        "imsize = 0.03 # this is the image size\n",
        "node_dict = {}\n",
        "for n, attr in h.nodes(data=True):\n",
        "    char_name = attr['attr_dict']['character']\n",
        "    path_to_image = attr['attr_dict']['path']\n",
        "    # print(f'Character {char_name}, Node: {n}')\n",
        "    (x,y) = pos[n]\n",
        "    xx,yy = trans((x,y)) # figure coordinates\n",
        "    xa,ya = trans2((xx,yy)) # axes coordinates\n",
        "    a = plt.axes([xa-imsize/2.0,ya-imsize/2.0, imsize, imsize ])\n",
        "    a.imshow(mpimg.imread(path_to_image))\n",
        "    a.set_aspect('equal')\n",
        "    a.axis('off')\n",
        "    node_dict[n] = (char_name, path_to_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsSBvqPOVxSW",
        "colab_type": "text"
      },
      "source": [
        "**Use graph algorithms to discover interesting insights regarding the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ZAuI8K-29t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "d = nx.pagerank(h)\n",
        "pg = max(dict(d).items(), key=operator.itemgetter(1))   \n",
        "pg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHjZmX5OVOOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "max_node_pg = pg[0]\n",
        "hero_name_pg = node_dict[max_node_pg][0].replace('_', ' ')\n",
        "print(f'The hero with the highest pagerank ({pg[1]}) is \"{hero_name_pg}\".')\n",
        "plt.imshow(mpimg.imread(node_dict[max_node_pg][1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl5IhWxij82v",
        "colab_type": "text"
      },
      "source": [
        "**According to Closeness Centrality who is the most central hero:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND86-7JA-3VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = nx.closeness_centrality(h) # can take some time to run\n",
        "\n",
        "cen = max(dict(d).items(), key=operator.itemgetter(1))\n",
        "cen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYqbOStMlPf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_node_cen = cen[0]\n",
        "hero_name_cen = node_dict[max_node_cen][0].replace('_', ' ')\n",
        "print(f'Closeness Centrality ({cen[1]}), who is the most central hero, is \"{hero_name_cen}\".')\n",
        "\n",
        "plt.imshow(mpimg.imread(node_dict[max_node_cen][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}